# Seonghee Lee

## Introduction
I am Seonghee Lee, a second-year Master's student in Computer Science at Stanford University, graduating in June 2025. My research lies at the intersection of Artificial Intelligence (AI), Human-Computer Interaction (HCI), and Accessibility. I specialize in designing innovative AI-integrated solutions that push the boundaries of interaction and accessibility technologies.

## Technical Expertise
- **Programming Languages:** Python, Java, JavaScript, C++, HTML/CSS
- **Frameworks and Tools:** PyTorch, TensorFlow, React, Node.js, Express, Docker, Git, OpenCV, Hugging Face Transformers
- **Domains:**
  - Machine Learning and Deep Learning
  - Vision and Natural Language Processing (NLP) Models
  - Accessibility-focused HCI Prototyping
  - Full-Stack Software Development

## Awards and Achievements
- **ACM/IEEE CHI 2024 Honorable Mention:** For the project 'Teach AI How to Code,' which developed an educational platform to assist users in learning programming through generative AI models.
- **ASSETS 2024:** Presented the award-winning paper, 'AltCanvas: A Tile-Based Image Editor with Generative AI for Blind or Visually Impaired People,' which received critical acclaim for advancing accessibility in image editing.
- **Conference Publications:**
  - "AltCanvas: Enhancing Visual Accessibility through Generative AI," published in ACM ASSETS 2024.
  - "Integrating Multimodal Agents in Shared Spaces: Challenges and Solutions," under review for ACM CHI 2025.
  - "StyleAligned: AI-Driven Generation of Tactile Graphics for Accessibility," presented at IEEE CVPR 2024 Workshop on AI for Accessibility.

## Research and Projects
- **AltCanvas:**
  - Designed and developed a novel tile-based image editor leveraging Stable Diffusion for generating accessible tactile graphics for Blind or Visually Impaired (BVI) individuals.
  - Conducted three-stage user studies to iteratively refine the system and ensure usability.

- **IRL Ditto:**
  - Led the integration of AI agents in open office spaces by combining computer vision, speech processing, and generative conversational models.
  - Developed logic frameworks for proxemic interactions and real-time engagement tracking.

- **StyleAligned:**
  - Researched and implemented AI-based tactile pattern generation for accessibility.
  - Developed algorithms to ensure controlled placement of tactile patterns, balancing usability and aesthetics.

## Experience
- **Microsoft Research:**
  - Interned in the Human-Computer AI Experiences (HCAIX) group, working on multimodal conversational agents and their applications in shared spaces.
  - Published findings on integrating agents with human-centered design principles.

- **Stanford NLP and HCI Group:**
  - AI Research Assistant under Professor Diyi Yang and Professor Hari Subramonyam focusing on fine-tuning large language models and building task-specific interactive AI agents.

- **Cochl.AI:**
  - Developed cutting-edge prototypes for AI-integrated audio systems in Mercedes Benz Cars, contributing to advancements in real-time audio analysis and enhancement.

## Hobbies and Interests
- Cooking and Interior Design

## Links
- [GitHub Profile](https://github.com/shljessie)
- [Portfolio](https://shljessie.github.io/)
- [LinkedIn](https://www.linkedin.com/in/seonghee-lee/)

## Contact
- Email: shlee@cs.stanford.edu
