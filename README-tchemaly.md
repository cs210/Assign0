## Hi!üëãüèª I'm Trishia El Chemaly

I am a Bioengineering PhD Candidate, highly motivated by impact. My research focus is in AR for surgery and HCI. I enjoy organizing and participating in hackathons. Previously, I was the president of [Stanford XR](https://www.stanfordxr.org/about) where I led several initiatives such as founding [Immerse The Bay](https://immersethebay.stanfordxr.org/), Stanford's leading XR hackathon. 

![DSC_0480 - Copy](https://github.com/user-attachments/assets/db255a87-0dc3-4daa-9f39-ce20efe6c178)

## üëìPast Experiences
**Student Researcher @ Google**
- Worked alongside the Google AR team that recently launched [Android XR](https://blog.google/products/android/android-xr/)
- Led the research and user studies on visual comfort and motion sickness for Moohan, Samsung's first headset powered by Android XR

**Graduate Research Assistant @ IMMERS (Incubator for Medical Mixed and Extended Reality at Stanford)**
- Implemented stereoscopic calibration for AR visualization in microscopic surgery
- Trained and fine-tuned computer vision models for tracking in surgical AR
- Developed AR solutions for medical needs identified while working with clinicians 
- Co-authored a CHI paper on interactive shape sonification for tumor localization in breast cancer surgery
- Mentored undergraduate students developing applications for diverse AR devices

**RAD206: Mixed-Reality in Medicine Teaching Assistant @ Stanford University**
- Created and graded AR assignments in Unity and C#
- Mentored groups of students working on class projects with Microsoft HoloLens 2

**CS 12SI: Spatial Computing Workshop Student Lecturer @ Stanford University**
- Co-created and co-led CS12SI, a course listed under Stanford's CS department, with fellow Stanford XR members
- Taught Stanford students skills to create AR applications for Apple Vision Pro, both device and simulator
  
**Project Experiences from Stanford Courses**
- CS 231N (CNNs for Visual Recignition): Brand Product Identification with Deep Learning
- CS 231A (Computer Vision: From 3D Reconstruction to Recognition): Automatic Tracking for Anatomical Landmarks 
- CS 224N (NLP with Deep Learning): Context-Aware Gesture Interpretation in AR/VR
- EE 267 (Virtual Reality): AR in Head and Neck Surgery
- Design 374 (Creativity in Research): ResQVision - AR Aid for Emergency Responders
- Design 284 (Designing for XR): Streamlining 3D Data Processing for ML 

## üìöSkills
**AR/VR Development** 
- Unity, C#, visionOS, AR Foundation, RealityKit, OpenXR, Blender
- Apple Vision Pro, Meta Quest 3 and Quest Pro, Microsoft HoloLens, Magic Leap

**CS**
- Computer Vision and Deep Learning: Python, MATLAB, Unity and C#
- Object-oriented Programming: C#, Python, JavaScript
- Signal and Image Processing, Computational Modeling: Python, MATLAB

## üìÑPortfolio
Learn more about me [here](https://tchemaly.github.io/)!
